{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA_Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQXKHrWzVfdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "455f4d15-c904-4240-cbd2-3a7a0d6e3452"
      },
      "source": [
        "!pip install --upgrade tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/7e/281edb5bc3274dfb894d90f4dbacfceaca381c2435ec6187a2c6f329aed7/tqdm-4.48.2-py2.py3-none-any.whl (68kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 27.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tqdm-4.48.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM4uXTyjRgAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88d36ad8-e7ec-459c-c469-31e70c57c9d2"
      },
      "source": [
        "!pip install keras==2.3.1\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8\n",
            "Collecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 55.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (49.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuwMx7zwVk8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3bd63da4-7c15-4140-f360-78601f2bb4da"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7y9v5oDVlx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5b161414-0e4b-46db-c17e-29b0bebe5303"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhZyPRyfVqBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83b50cf3-bb8d-44e8-dc0e-4b1fbfd1973d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXbAVQjfVzsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "9653138b-1796-4599-a053-7b0cf5eef442"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 14981035827346275982, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 10283619849575470539\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 6341950347768077148\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15788201792\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 16495229112861778046\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vujs7lAiV3hT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "f161ed55-1f23-4c7a-ac62-7f15725e7ca7"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       26751672 kB\n",
            "MemFree:        14759728 kB\n",
            "MemAvailable:   25494300 kB\n",
            "Buffers:          158740 kB\n",
            "Cached:         10500852 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1013100 kB\n",
            "Inactive:       10212240 kB\n",
            "Active(anon):     463900 kB\n",
            "Inactive(anon):     8592 kB\n",
            "Active(file):     549200 kB\n",
            "Inactive(file): 10203648 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              2020 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        565952 kB\n",
            "Mapped:           449192 kB\n",
            "Shmem:              9160 kB\n",
            "Slab:             464056 kB\n",
            "SReclaimable:     398844 kB\n",
            "SUnreclaim:        65212 kB\n",
            "KernelStack:        4528 kB\n",
            "PageTables:         6644 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:    13375836 kB\n",
            "Committed_AS:    2958628 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1904 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      216252 kB\n",
            "DirectMap2M:     7122944 kB\n",
            "DirectMap1G:    22020096 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrhKLoiMoFXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "12e1e022-cec9-46da-9076-442df5aca9e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwD-KY6voNg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/3-class.csv 3-class.csv"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t34yXZ2ob38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/stop_words.txt stop_words.txt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nuz7UmEmouTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "6cf79def-ef24-4177-d9e9-72be991a7219"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlinBackend.figure_format = 'retina'\n",
        "df = pd.read_csv('3-class.csv')\n",
        "df.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>الاعلام اللبناني يهاجم السعوديه منذ مده بكل ق...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>البرنامج استاجر بعض المشاهير و الهوامير في تو...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>الخرج بيض الله وجه محافظ الخرج فهذه القناه تص...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>الرياض السعوديه رسالتي لوزير العمل في حينه عن...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Polarity\n",
              "0   ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...      neg\n",
              "1   اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...      neg\n",
              "2   اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...      neg\n",
              "3   اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...      neg\n",
              "4   الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...      neg\n",
              "5   الاعلام اللبناني يهاجم السعوديه منذ مده بكل ق...      neg\n",
              "6   البرنامج استاجر بعض المشاهير و الهوامير في تو...      neg\n",
              "7   الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا...      neg\n",
              "8   الخرج بيض الله وجه محافظ الخرج فهذه القناه تص...      neg\n",
              "9   الرياض السعوديه رسالتي لوزير العمل في حينه عن...      neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV6oCwqApCqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "78fda252-c5b0-4678-f62e-ed77ec763369"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56674 entries, 0 to 56673\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Tweet     56674 non-null  object\n",
            " 1   Polarity  56674 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 885.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-00vtx2_pLwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a7efa36b-977a-493e-d92d-7776c8153847"
      },
      "source": [
        "df.Polarity.value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neg     20731\n",
              "neut    18726\n",
              "pos     17217\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hu1CFuvpV-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Polarity'] = df['Polarity'].map({'neg': 0, 'pos': 1, 'neut': 2})"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRBTZLXup8Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "df0f1470-23c7-4dfe-b4dc-87b1307a9cec"
      },
      "source": [
        "df[df.Polarity == 0].head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>الاعلام اللبناني يهاجم السعوديه منذ مده بكل ق...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>البرنامج استاجر بعض المشاهير و الهوامير في تو...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>الخرج بيض الله وجه محافظ الخرج فهذه القناه تص...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>الرياض السعوديه رسالتي لوزير العمل في حينه عن...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Polarity\n",
              "0   ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...         0\n",
              "1   اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...         0\n",
              "2   اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...         0\n",
              "3   اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...         0\n",
              "4   الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...         0\n",
              "5   الاعلام اللبناني يهاجم السعوديه منذ مده بكل ق...         0\n",
              "6   البرنامج استاجر بعض المشاهير و الهوامير في تو...         0\n",
              "7   الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا...         0\n",
              "8   الخرج بيض الله وجه محافظ الخرج فهذه القناه تص...         0\n",
              "9   الرياض السعوديه رسالتي لوزير العمل في حينه عن...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLbe70O-p-H8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "fa4147ee-d519-4562-ce0a-c7c54cd17dd8"
      },
      "source": [
        "df[df.Polarity == 1].head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39457</th>\n",
              "      <td>ssr true اشكر قناه واشكر الاخوان في منتدى توا...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39458</th>\n",
              "      <td>احلام الملكه بانوراما_fm منوره احلام</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39459</th>\n",
              "      <td>احلى ديو علا الفارس علي الغفيلي في اسبوع</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39460</th>\n",
              "      <td>احلى قعده مع احلى رفقات</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39461</th>\n",
              "      <td>احلى قعده مع الاصدقاا</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39462</th>\n",
              "      <td>الحمدلله كانت حفله حلوه وناجحه ومنشكر اهل الم...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39463</th>\n",
              "      <td>الكبار برنامج سيساهم في زياده وعي اللاعب السع...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39464</th>\n",
              "      <td>امجد يا شاكر يا قرشي نتمنا ليك التوفيق و انشا...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39465</th>\n",
              "      <td>انا وحبيبتي الفنانه القديره لطيفه من وسط بيرو...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39466</th>\n",
              "      <td>اولا العفو والشكر لكم وجزاكم الله الف خير لكل...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tweet  Polarity\n",
              "39457   ssr true اشكر قناه واشكر الاخوان في منتدى توا...         1\n",
              "39458              احلام الملكه بانوراما_fm منوره احلام          1\n",
              "39459          احلى ديو علا الفارس علي الغفيلي في اسبوع          1\n",
              "39460                           احلى قعده مع احلى رفقات          1\n",
              "39461                             احلى قعده مع الاصدقاا          1\n",
              "39462   الحمدلله كانت حفله حلوه وناجحه ومنشكر اهل الم...         1\n",
              "39463   الكبار برنامج سيساهم في زياده وعي اللاعب السع...         1\n",
              "39464   امجد يا شاكر يا قرشي نتمنا ليك التوفيق و انشا...         1\n",
              "39465   انا وحبيبتي الفنانه القديره لطيفه من وسط بيرو...         1\n",
              "39466   اولا العفو والشكر لكم وجزاكم الله الف خير لكل...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L78uHb3rMSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "afe808f7-d8b3-4655-9f9f-c09177e8722a"
      },
      "source": [
        "df[df.Polarity == 2].head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20731</th>\n",
              "      <td>FM الاان عن هوايه التطعيس في المنطقه و الاهتم...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20732</th>\n",
              "      <td>اقصد برنامج اصرار على قناه تعرض الان</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20733</th>\n",
              "      <td>الاستاذ محمد الحميدي ضيف في برنامج الثامنه_مع...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20734</th>\n",
              "      <td>الان في الطائره واجمل مفاجاه من و لوين بتتوقع...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20735</th>\n",
              "      <td>البرنسيسه منال_موسى و سفير الالحان فايز_السعي...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20736</th>\n",
              "      <td>الثلاثااالفنانه نوال_الزغبي ضيفه العلاميه وفا...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20737</th>\n",
              "      <td>الفيلسوف يوسف الثنيان في برنامج مع الكبار على...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20738</th>\n",
              "      <td>اللي له خلق يتابع الساعه 12 30 على mbc برنامج...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20739</th>\n",
              "      <td>الليله الاسطوره يوسف الثنيان عبر برنامج الكبا...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20740</th>\n",
              "      <td>الليله حلقه نوال_الزغبي في المتاهه على شاشه i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tweet  Polarity\n",
              "20731   FM الاان عن هوايه التطعيس في المنطقه و الاهتم...         2\n",
              "20732              اقصد برنامج اصرار على قناه تعرض الان          2\n",
              "20733   الاستاذ محمد الحميدي ضيف في برنامج الثامنه_مع...         2\n",
              "20734   الان في الطائره واجمل مفاجاه من و لوين بتتوقع...         2\n",
              "20735   البرنسيسه منال_موسى و سفير الالحان فايز_السعي...         2\n",
              "20736   الثلاثااالفنانه نوال_الزغبي ضيفه العلاميه وفا...         2\n",
              "20737   الفيلسوف يوسف الثنيان في برنامج مع الكبار على...         2\n",
              "20738   اللي له خلق يتابع الساعه 12 30 على mbc برنامج...         2\n",
              "20739   الليله الاسطوره يوسف الثنيان عبر برنامج الكبا...         2\n",
              "20740   الليله حلقه نوال_الزغبي في المتاهه على شاشه i...         2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1w0HBI-ariF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "548f8f01-f70a-4991-e556-7e78d0790030"
      },
      "source": [
        "df['Tweet'].nunique()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebxDBDx3atse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86ec9aca-5177-4ab5-8f37-b7ae4c0a5456"
      },
      "source": [
        "repeat=[]\n",
        "list_of_tweets = df['Tweet'].to_list()\n",
        "for i in range(len(list_of_tweets)-1):\n",
        "  if list_of_tweets[i] in list_of_tweets[i+1:]:\n",
        "    repeat.append(i)\n",
        "len(repeat)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhZltNXKazSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cab00360-3bf1-4fbe-f29f-d7acf7e31e40"
      },
      "source": [
        "df.drop(repeat,axis=0,inplace=True)\n",
        "len(df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmZ7-lXya35k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1e9f3619-d28a-4693-90b5-753852fbdf28"
      },
      "source": [
        "df.reset_index(drop=True, inplace=True)\n",
        "df.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 55176 entries, 0 to 55175\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Tweet     55176 non-null  object\n",
            " 1   Polarity  55176 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 862.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJXz8NSKr4w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "074f780f-d7ed-47e8-c459-3ec884b4303a"
      },
      "source": [
        "df.Polarity.value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    19944\n",
              "2    18285\n",
              "1    16947\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECHSnfkWRtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df.Tweet\n",
        "y = df.Polarity"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAPpasJWvpn1",
        "colab_type": "text"
      },
      "source": [
        "###Data Preparartion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aORnf61Bv4m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['pre_clean_len'] = [len(t) for t in df.Tweet]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6WheXAW5Yem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data cleaning function definition\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipySzOTD59xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "pat1 = r'@[A-Za-z0-9_]+'\n",
        "pat2 = r'https?://[^ ]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "www_pat = r'www.[^ ]+'\n",
        "arabic_num_pat = '[٠١٢٣٤٥٦٧٨٩]'\n",
        "eng_num_pat = '[0123456789]'\n",
        "sharta_pat = '[_]'\n",
        "#sharta_pat = '_[أ-ي]+' #for removing hashtag\n",
        "eng_pat = '[A-Za-z]'\n",
        "\n",
        "def tweet_cleaner(text):\n",
        "  soup = BeautifulSoup(text, 'lxml')\n",
        "  souped = soup.get_text()\n",
        "  try:\n",
        "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "  except:\n",
        "        bom_removed = souped\n",
        "  stripped = re.sub(combined_pat, '', bom_removed)\n",
        "  stripped = re.sub(www_pat, '', stripped)\n",
        "  stripped = re.sub(arabic_num_pat, '', stripped)\n",
        "  stripped = re.sub(eng_num_pat, '', stripped)\n",
        "  #stripped = re.sub(r'\\w+_\\s?','_',stripped) #for removing hashtag\n",
        "  stripped = re.sub(sharta_pat, ' ', stripped)\n",
        "  stripped = re.sub(eng_pat, ' ', stripped)\n",
        "\n",
        "  words = [x for x in tok.tokenize(stripped) if len(x) > 1]\n",
        "  return (\" \".join(words)).strip()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vzDOrZCWsPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stopword function\n",
        "import codecs\n",
        "\n",
        "def get_stop_words():\n",
        "    path = 'stop_words.txt'\n",
        "    stop_words = []\n",
        "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
        "        stop_words = myfile.readlines()\n",
        "    stop_words = [word.strip() for word in stop_words]\n",
        "    return stop_words\n",
        "\n",
        "stop_words = get_stop_words()\n",
        "\n",
        "def remove_stop_words(strList):\n",
        "  resList = []\n",
        "  for i in range(0, len(strList)):\n",
        "    if(strList[i] not in stop_words):\n",
        "      resList.append(strList[i])\n",
        "  return ' '.join(resList)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlW8s5AVCC38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e710f5cb-784c-4d8c-e0c0-04546e6b2edf"
      },
      "source": [
        "clean_tweet_texts = []\n",
        "for i in range(0, len(df)):\n",
        "  if( (i+1)%10000 == 0 ):\n",
        "        print(\"Tweets %d of %d has been processed\"%(i+1,len(df)))                                                                    \n",
        "  #clean_tweet_texts.append(remove_stop_words(tweet_cleaner(df['Tweet'][i]).split(' ')))\n",
        "  clean_tweet_texts.append(tweet_cleaner(df['Tweet'][i]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweets 10000 of 55176 has been processed\n",
            "Tweets 20000 of 55176 has been processed\n",
            "Tweets 30000 of 55176 has been processed\n",
            "Tweets 40000 of 55176 has been processed\n",
            "Tweets 50000 of 55176 has been processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGZHXprAHWmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "211c4a1b-21a9-416b-fa8f-5912bb011476"
      },
      "source": [
        "clean_tweet_texts[:10]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ابراهيم عيسى الوسخ ابن الوسخه كلما حصل حادث اتهم السعوديه بالارهاب الكلب كان براتب مليون جنيه من سنوي مصر',\n",
              " 'اخطر حروب الارض حرب العقيده حسيبك الله اول ال راه يم رب عل نا وق ده الع يده وات زا',\n",
              " 'اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خبثها اين مسؤولي الجمعيه من هذا نطالب خادم الحرمين بايقاف',\n",
              " 'اعلامنا متمثل في داوودالشريان روتانا وطقتهم كيف ترجي من هالاشكال خير همهم الوحيد في الحياه قياده المراه للسياره',\n",
              " 'الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه قناه العهر مزجاه في جميع المجالات',\n",
              " 'الاعلام اللبناني يهاجم السعوديه منذ مده بكل قبيح ومجموعه تدعم الاعلام في لبنان باقامه برامجها الضخمه فيها',\n",
              " 'البرنامج استاجر بعض المشاهير الهوامير في تويتر عشان يبررو لهم ويرقعو لقناه برنامج اصرار',\n",
              " 'الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا همه الشحاذه من على حساب مواطن يفضح برنامج الاصرار برعايه',\n",
              " 'الخرج بيض الله وجه محافظ الخرج فهذه القناه تصب على المسلمين سيل من المخالفات الشرعيه والمحرمات تدعو الى الرذيله وتشوه صوره الاسلام',\n",
              " 'الرياض السعوديه رسالتي لوزير العمل في حينه عن برنامج اصرار برنامج حتي بفكرته منسوخ بشكل مبتذل وفاشل']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDss3S9uFUEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72349e5d-5b05-49f5-9b97-3cd06c9ff2fa"
      },
      "source": [
        "len(clean_tweet_texts)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu_LoP3cGlUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalization\n",
        "def normalizeArabic(text):\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    return(text)\n",
        "for i in range(len(clean_tweet_texts)):\n",
        "  clean_tweet_texts[i] = normalizeArabic(clean_tweet_texts[i])\n",
        "#repeated letters\n",
        "import re\n",
        "for i in range(len(clean_tweet_texts)):\n",
        "  clean_tweet_texts[i] = re.sub(r'(.)\\1+', r'\\1\\1', clean_tweet_texts[i])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xrjnuxlDPqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df = pd.DataFrame(clean_tweet_texts, columns=['text'])\n",
        "clean_df['target'] = df.Polarity\n",
        "clean_df.to_csv('/content/drive/My Drive/clean_tweet.csv', encoding='utf-8')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H6e4zCP3Sitm",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/clean_tweet.csv /content/"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7f5Q3UAShkU",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlinBackend.figure_format = 'retina'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VUwtEhbcqbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4dea860d-6d24-4a59-a040-994fd904ea6d"
      },
      "source": [
        "csv = '/content/drive/My Drive/clean_tweet.csv'\n",
        "my_df = pd.read_csv(csv, index_col=0)\n",
        "my_df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ابراهيم عيسي الوسخ ابن الوسخه كلما حصل حادث ات...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اخطر حروب الارض حرب العقيده حسيبك الله اول ال ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اعلامنا متمثل في داوودالشريان روتانا وطقتهم كي...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  ابراهيم عيسي الوسخ ابن الوسخه كلما حصل حادث ات...       0\n",
              "1  اخطر حروب الارض حرب العقيده حسيبك الله اول ال ...       0\n",
              "2  اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خ...       0\n",
              "3  اعلامنا متمثل في داوودالشريان روتانا وطقتهم كي...       0\n",
              "4  الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه ...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_TsqTC8cxRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "4767d88b-54db-4f39-dcb2-f616dc892174"
      },
      "source": [
        "my_df.info()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 55176 entries, 0 to 55175\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    55175 non-null  object\n",
            " 1   target  55176 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMwBZrMZc16e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "52ca27d5-b3f5-472a-b32e-bfd408723046"
      },
      "source": [
        "my_df.dropna(inplace=True)\n",
        "my_df.reset_index(drop=True, inplace=True)\n",
        "my_df.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 55175 entries, 0 to 55174\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    55175 non-null  object\n",
            " 1   target  55175 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 862.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O4IehAzdsrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = my_df.text\n",
        "y = my_df.target"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfOb-XOoc91b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "SEED = 666\n",
        "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.2, random_state=SEED)\n",
        "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiQ8oEm0dpfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "de61cefe-0ee9-4f20-9d3f-9aa783e930ac"
      },
      "source": [
        "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive, {3:.2f}% neutral\".format(len(x_train),\n",
        "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
        "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100,\n",
        "                                                                            (len(x_train[y_train == 2]) / (len(x_train)*1.))*100))\n",
        "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive, {3:.2f}% neutral\".format(len(x_validation),\n",
        "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
        "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100,\n",
        "                                                                            (len(x_validation[y_validation == 2]) / (len(x_validation)*1.))*100))\n",
        "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive, {3:.2f}% neutral\".format(len(x_test),\n",
        "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
        "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100,\n",
        "                                                                            (len(x_test[y_test == 2]) / (len(x_test)*1.))*100))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has total 44140 entries with 36.14% negative, 30.83% positive, 33.03% neutral\n",
            "Validation set has total 5517 entries with 36.52% negative, 30.40% positive, 33.08% neutral\n",
            "Test set has total 5518 entries with 35.83% negative, 30.10% positive, 34.07% neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sr2yuopPkbz0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a032aa98-a549-4d58-e149-6c80adc2932b"
      },
      "source": [
        "#converting the labels to categorical data\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_train.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44140, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmujBZdFkcL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_validation = to_categorical(y_validation)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW73-Bbjkhpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd15e0fc-8b48-492a-bc10-01fe74d5602f"
      },
      "source": [
        "y_validation.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5517, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eiL-stPco2L",
        "colab_type": "text"
      },
      "source": [
        "#**word to vector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jG165zUcllu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF37zGp9dHNp",
        "colab_type": "text"
      },
      "source": [
        "##**Arabic news**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9YGyNkqdOTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/arabic-news.bin /content/"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxERc7JdPbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4557d947-25c5-4414-9c0e-f9c7eafddf80"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "ArabicNews_embedding = KeyedVectors.load_word2vec_format('arabic-news.bin', binary=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aumo29jdU9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1b9fc5e7-5500-4a59-d7ee-50f1606f66db"
      },
      "source": [
        "len(ArabicNews_embedding.wv.vocab.keys())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBY2fVADdsBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9950617f-9fb2-4fd7-cb88-19e2e844dbd4"
      },
      "source": [
        "embeddings_index_arabicnews = {}\n",
        "for w in ArabicNews_embedding.wv.vocab.keys():\n",
        "  embeddings_index_arabicnews[w] = ArabicNews_embedding.wv[w], \n",
        "print(f'Found {len(embeddings_index_arabicnews)} word vectors.')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 159175 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLjSOyE4d7JQ",
        "colab_type": "text"
      },
      "source": [
        "##**Fasttext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSo6xscd9xE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "a3226288-7a20-443a-8122-986992747f9f"
      },
      "source": [
        "#Run this shell to get the fast-text word embeddings\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ar.vec"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-12 20:20:55--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ar.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1610017300 (1.5G) [binary/octet-stream]\n",
            "Saving to: ‘wiki.ar.vec’\n",
            "\n",
            "wiki.ar.vec         100%[===================>]   1.50G  12.1MB/s    in 2m 9s   \n",
            "\n",
            "2020-08-12 20:23:05 (11.9 MB/s) - ‘wiki.ar.vec’ saved [1610017300/1610017300]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiI4YjVEeEd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "275ae673-7bbb-4206-d15f-b4a9230dbf8d"
      },
      "source": [
        "# Run this shell to load the downloaded word-embeddings\n",
        "from gensim.models import KeyedVectors\n",
        "def load_w2v(path, binary):\n",
        "    return KeyedVectors.load_word2vec_format(fname=path, binary=binary)\n",
        "w2v = load_w2v('./wiki.ar.vec', binary=False)\n",
        "w2v_embeddings = w2v.get_keras_embedding()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbNpCx4SeH2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "af690f39-4742-4df9-a5a7-f68cd38a8f1c"
      },
      "source": [
        "len(w2v.wv.vocab.keys())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "610977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPwruyIieK0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "985de427-4877-41e6-a9e3-cd51a106d29a"
      },
      "source": [
        "embeddings_index_fasttext = {}\n",
        "for w in w2v.wv.vocab.keys():\n",
        "  embeddings_index_fasttext[w] = w2v[w]\n",
        "print(f'Found {len(embeddings_index_fasttext)} word vectors.')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 610977 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiWJmXRLeY1v",
        "colab_type": "text"
      },
      "source": [
        "##**AraVec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL0pOiA1eOGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/full_uni_cbow_100_twitter.zip /content/"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWSf7wz-ei82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/full_uni_sg_100_twitter.zip /content/"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em6Sadnceltb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "67b8f2d2-6975-4e36-808b-52830b88e139"
      },
      "source": [
        "!unzip full_uni_cbow_100_twitter.zip"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  full_uni_cbow_100_twitter.zip\n",
            "  inflating: full_uni_cbow_100_twitter.mdl  \n",
            "  inflating: full_uni_cbow_100_twitter.mdl.trainables.syn1neg.npy  \n",
            "  inflating: full_uni_cbow_100_twitter.mdl.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP2Fd1MPeorj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "277d81d8-a995-4f88-a53e-b79455307e7b"
      },
      "source": [
        "!unzip full_uni_sg_100_twitter.zip"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  full_uni_sg_100_twitter.zip\n",
            "  inflating: full_uni_sg_100_twitter.mdl  \n",
            "  inflating: full_uni_sg_100_twitter.mdl.trainables.syn1neg.npy  \n",
            "  inflating: full_uni_sg_100_twitter.mdl.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ycWq1ser2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f9f64b95-4d2c-4d4e-9a4f-1f585c9b4fe2"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model_ug_cbow = KeyedVectors.load('full_uni_cbow_100_twitter.mdl')\n",
        "model_ug_sg = KeyedVectors.load('full_uni_cbow_100_twitter.mdl')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C16nHRyFewqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e86b4b61-5f04-42e8-da92-0d702c6019fa"
      },
      "source": [
        "len(model_ug_cbow.wv.vocab.keys())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1259756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyMUbEVbexaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eaef57e3-f291-4a01-db22-047dda4dd31a"
      },
      "source": [
        "embeddings_index_aravec = {}\n",
        "for w in model_ug_cbow.wv.vocab.keys():\n",
        "  embeddings_index_aravec[w] = np.append(model_ug_cbow.wv[w], \n",
        "                                  model_ug_sg.wv[w])\n",
        "print(f'Found {len(embeddings_index_aravec)} word vectors.')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1259756 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXpvUaIcXK1l",
        "colab_type": "text"
      },
      "source": [
        "##Pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swk3yKJjUAvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences = tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacbNhkvVVmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42a75463-7942-46ef-d3f2-b7eb70d4bdb2"
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0VBOzHVY0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d242a167-f6e9-4582-97ca-4e917d0329f6"
      },
      "source": [
        "for x in x_train[:5]:\n",
        "  print(x)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "صوره النص الكامل الاوامر الملكيه التي صدرت اليوم اوامر ملكيه اعفاا عزام الدخيل الوزراا الجدد\n",
            "اسكت اسكت اهو الهلال مغلوب الدقيقه\n",
            "روما لا يمثل الكالتشيو روما من الدوري الهندي برشلونه روما\n",
            "العراق تجدد الاشتباكات بين الحشد الشعبي والبشمركه يكيتي ميديا\n",
            "هذا اللي يقلع اسنان حارس الخليج ليه ماوقفوه اين لجنه الانظباط النصر النصر الاتحاد الهلال هجر\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5FjwfNVjcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = []\n",
        "for x in x_train:\n",
        "  length.append(len(x.split()))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfnor6gRVyt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c651f5b0-5e1f-4dbf-99d5-14990647d835"
      },
      "source": [
        "tweetlen=max(length)\n",
        "tweetlen"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrbgQobVz_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1246691-34ad-4a9d-8d0c-65752473cfec"
      },
      "source": [
        "x_train_seq = pad_sequences(sequences, maxlen=tweetlen)\n",
        "print('Shape of data tensor: ', x_train_seq.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor:  (44140, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1u0kjKV9OR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "8b1f129b-1b3e-4cd6-c465-687f45dfcf56"
      },
      "source": [
        "x_train_seq[:5]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,   347,  3604,  6102,  1841,\n",
              "         1410,   138,  9385,    43,    52,    55,   268,   116,   139,\n",
              "          541,  3605],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,  5655,  5655, 20856,     1,\n",
              "        15812,   677],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,    11,    18,  2569,  6103,    11,     3,    94,  8322,\n",
              "           10,    11],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,   471, 12975,  8323,   137,   240,   246, 20857,\n",
              "        31288, 10975],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,    28,    38,  9386, 31289,   855,\n",
              "          266,   353, 31290,   465,   607,  9387,    13,    13,    17,\n",
              "            1,    26]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucqpAKnpWAHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
        "x_val_seq = pad_sequences(sequences_val, maxlen=tweetlen)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55v0rpHYK-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 3\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.embeddings import Embedding\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3n12_TEklMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "x_test_seq = pad_sequences(sequences_test, maxlen=tweetlen)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWMHLs8wS44A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "6b89d897-60f1-4ac6-ec0b-3a749c43295c"
      },
      "source": [
        "!pip install keras_metrics"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPM54EYZV-G3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras_metrics\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "import shutil"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qO17puh2Fxi-"
      },
      "source": [
        "#**GRU-AraVec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9yMyUNPepcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 100000\n",
        "embedding_matrix_aravec = np.zeros((num_words, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i >= num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index_aravec.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix_aravec[i] = embedding_vector"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-6CXZrdXFxjC",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=\"./logs/gru_aravec\")\n",
        "keras_callbacks = [tensorboard]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK92C9t26eFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "04863032-72e2-472d-f68f-6359e8e322d6"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "gru_aravec = Sequential() \n",
        "e = Embedding(100000, 200, weights=[embedding_matrix_aravec], input_length=tweetlen\n",
        "              , trainable=True)\n",
        "gru_aravec.add(e)\n",
        "gru_aravec.add(keras.layers.GRU(100, dropout=0.2))\n",
        "gru_aravec.add(Dense(3, activation='softmax'))\n",
        "gru_aravec.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), \n",
        "                           keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "print(gru_aravec.summary())\n",
        "history = gru_aravec.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=64, callbacks=keras_callbacks)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 29, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100)               90300     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 20,090,603\n",
            "Trainable params: 20,090,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44140 samples, validate on 5517 samples\n",
            "Epoch 1/5\n",
            "  256/44140 [..............................] - ETA: 7:40 - loss: 1.2503 - accuracy: 0.3242 - precision: 0.3232 - recall: 0.2517 - f1_score: 0.2798"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.108397). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "44140/44140 [==============================] - 53s 1ms/step - loss: 0.6857 - accuracy: 0.7066 - precision: 0.6679 - recall: 0.5791 - f1_score: 0.6196 - val_loss: 0.5620 - val_accuracy: 0.7711 - val_precision: 0.7849 - val_recall: 0.7456 - val_f1_score: 0.7647\n",
            "Epoch 2/5\n",
            "44140/44140 [==============================] - 50s 1ms/step - loss: 0.5138 - accuracy: 0.7900 - precision: 0.8090 - recall: 0.7726 - f1_score: 0.7904 - val_loss: 0.5361 - val_accuracy: 0.7839 - val_precision: 0.8111 - val_recall: 0.7514 - val_f1_score: 0.7800\n",
            "Epoch 3/5\n",
            "44140/44140 [==============================] - 51s 1ms/step - loss: 0.4346 - accuracy: 0.8269 - precision: 0.8437 - recall: 0.8188 - f1_score: 0.8310 - val_loss: 0.5288 - val_accuracy: 0.7910 - val_precision: 0.8230 - val_recall: 0.7675 - val_f1_score: 0.7941\n",
            "Epoch 4/5\n",
            "44140/44140 [==============================] - 50s 1ms/step - loss: 0.3659 - accuracy: 0.8569 - precision: 0.8779 - recall: 0.8577 - f1_score: 0.8676 - val_loss: 0.5334 - val_accuracy: 0.7881 - val_precision: 0.8061 - val_recall: 0.7639 - val_f1_score: 0.7843\n",
            "Epoch 5/5\n",
            "44140/44140 [==============================] - 51s 1ms/step - loss: 0.3002 - accuracy: 0.8859 - precision: 0.9080 - recall: 0.8896 - f1_score: 0.8987 - val_loss: 0.5694 - val_accuracy: 0.7863 - val_precision: 0.8312 - val_recall: 0.7172 - val_f1_score: 0.7698\n",
            "CPU times: user 8min 43s, sys: 1min 21s, total: 10min 5s\n",
            "Wall time: 4min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xHmF1CClFxjH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b15f55b2-c4d6-4f8e-b437-a674ed0bba95"
      },
      "source": [
        "gru_aravec.evaluate(x_test_seq, y_test) "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5518/5518 [==============================] - 1s 271us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5626454903795133,\n",
              " 0.7908662557601929,\n",
              " 0.8360812664031982,\n",
              " 0.6995382308959961,\n",
              " 0.7612729668617249]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PqiM6CwZFxjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ca5955d-409c-4e04-b9e1-b6a7f56d7b2f"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = gru_aravec.to_json()\n",
        "with open(\"/content/drive/My Drive/3-class/gru_aravec/gru_aravec.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "gru_aravec.save_weights(\"/content/drive/My Drive/3-class/gru_aravec/gru_aravec.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6ueseB1FxjL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b02c5e7-8f9b-45d5-b471-ec577b56502f"
      },
      "source": [
        "import shutil\n",
        "shutil.move('/content/logs/gru_aravec','/content/drive/My Drive/3-class/gru_aravec/gru_aravec')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3-class/gru_aravec/gru_aravec'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zg4RxzApHPDN"
      },
      "source": [
        "#**LSTM-AraVec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-M7W8sKxHPDP",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=\"./logs/lstm_aravec\")\n",
        "keras_callbacks = [tensorboard]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JOKYqWw7HPDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "0064e03b-345f-40b8-bf21-f6b2b9202d37"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "lstm_aravec = Sequential() \n",
        "e = Embedding(100000, 200, weights=[embedding_matrix_aravec], input_length=tweetlen\n",
        "              , trainable=True)\n",
        "lstm_aravec.add(e)\n",
        "lstm_aravec.add(keras.layers.LSTM(100, dropout=0.2))\n",
        "lstm_aravec.add(Dense(3, activation='softmax'))\n",
        "lstm_aravec.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), \n",
        "                           keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "print(lstm_aravec.summary())\n",
        "history = lstm_aravec.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=64, callbacks=keras_callbacks)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 29, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 20,120,703\n",
            "Trainable params: 20,120,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44140 samples, validate on 5517 samples\n",
            "Epoch 1/5\n",
            "  320/44140 [..............................] - ETA: 2:11 - loss: 1.0978 - accuracy: 0.4250 - precision: 0.5186 - recall: 0.1203 - f1_score: 0.1935"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.141841). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "44140/44140 [==============================] - 44s 990us/step - loss: 0.6479 - accuracy: 0.7272 - precision: 0.7083 - recall: 0.5924 - f1_score: 0.6416 - val_loss: 0.5548 - val_accuracy: 0.7801 - val_precision: 0.8144 - val_recall: 0.7122 - val_f1_score: 0.7597\n",
            "Epoch 2/5\n",
            "44140/44140 [==============================] - 42s 954us/step - loss: 0.4995 - accuracy: 0.7968 - precision: 0.8171 - recall: 0.7729 - f1_score: 0.7944 - val_loss: 0.5343 - val_accuracy: 0.7858 - val_precision: 0.8179 - val_recall: 0.7283 - val_f1_score: 0.7703\n",
            "Epoch 3/5\n",
            "44140/44140 [==============================] - 42s 953us/step - loss: 0.4226 - accuracy: 0.8328 - precision: 0.8533 - recall: 0.8248 - f1_score: 0.8388 - val_loss: 0.5291 - val_accuracy: 0.7896 - val_precision: 0.8085 - val_recall: 0.7661 - val_f1_score: 0.7866\n",
            "Epoch 4/5\n",
            "44140/44140 [==============================] - 42s 962us/step - loss: 0.3509 - accuracy: 0.8629 - precision: 0.8819 - recall: 0.8578 - f1_score: 0.8696 - val_loss: 0.5534 - val_accuracy: 0.7827 - val_precision: 0.8482 - val_recall: 0.6879 - val_f1_score: 0.7596\n",
            "Epoch 5/5\n",
            "44140/44140 [==============================] - 42s 952us/step - loss: 0.2881 - accuracy: 0.8896 - precision: 0.9041 - recall: 0.8828 - f1_score: 0.8933 - val_loss: 0.5760 - val_accuracy: 0.7852 - val_precision: 0.8234 - val_recall: 0.7451 - val_f1_score: 0.7822\n",
            "CPU times: user 7min 26s, sys: 1min 14s, total: 8min 41s\n",
            "Wall time: 3min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-BIQI75HPDU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "521c337e-68f6-40e1-ca78-3f12475076c3"
      },
      "source": [
        "lstm_aravec.evaluate(x_test_seq, y_test) "
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5518/5518 [==============================] - 1s 235us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5773784074069539,\n",
              " 0.7935846447944641,\n",
              " 0.8336465358734131,\n",
              " 0.7362141609191895,\n",
              " 0.7817967534065247]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AoklmFjYHPDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7593437e-6575-4994-f638-2cf0c31c3515"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = lstm_aravec.to_json()\n",
        "with open(\"/content/drive/My Drive/3-class/lstm_aravec/lstm_aravec.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "lstm_aravec.save_weights(\"/content/drive/My Drive/3-class/lstm_aravec/lstm_aravec.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BWWjo3QJHPDY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8f901e4-0a01-495e-a0fd-f31322fb33a9"
      },
      "source": [
        "shutil.move('/content/logs/lstm_aravec','/content/drive/My Drive/3-class/lstm_aravec/lstm_aravec')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3-class/lstm_aravec/lstm_aravec'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKno9VZ6EO6v",
        "colab_type": "text"
      },
      "source": [
        "#**GRU-ArabicNews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLWvmYj-ENNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 100000\n",
        "embedding_matrix_arabicnews = np.zeros((num_words, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i >= num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index_arabicnews.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix_arabicnews[i] = np.empty_like(embedding_vector)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3h0h-dDFDLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=\"./logs/gru_arabicnews\")\n",
        "keras_callbacks = [tensorboard]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3CJ44LvFJS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "c1064eec-37a1-42f9-c565-d9099aedd276"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "gru_arabicnews = Sequential() \n",
        "e = Embedding(100000, 300, weights=[embedding_matrix_arabicnews], input_length=tweetlen\n",
        "              , trainable=True)\n",
        "gru_arabicnews.add(e)\n",
        "gru_arabicnews.add(keras.layers.GRU(100, dropout=0.2))\n",
        "gru_arabicnews.add(Dense(3, activation='softmax'))\n",
        "gru_arabicnews.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), \n",
        "                           keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "print(gru_arabicnews.summary())\n",
        "history = gru_arabicnews.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=64, callbacks=keras_callbacks)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 29, 300)           30000000  \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 100)               120300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 30,120,603\n",
            "Trainable params: 30,120,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44140 samples, validate on 5517 samples\n",
            "Epoch 1/5\n",
            "  256/44140 [..............................] - ETA: 3:07 - loss: 1.1786 - accuracy: 0.3711 - precision: 0.4232 - recall: 0.2461 - f1_score: 0.3098"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.180776). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "44140/44140 [==============================] - 53s 1ms/step - loss: 0.8779 - accuracy: 0.5917 - precision: 0.5631 - recall: 0.3576 - f1_score: 0.4352 - val_loss: 0.7009 - val_accuracy: 0.7018 - val_precision: 0.7534 - val_recall: 0.5999 - val_f1_score: 0.6677\n",
            "Epoch 2/5\n",
            "44140/44140 [==============================] - 52s 1ms/step - loss: 0.5771 - accuracy: 0.7622 - precision: 0.7719 - recall: 0.6840 - f1_score: 0.7249 - val_loss: 0.6288 - val_accuracy: 0.7415 - val_precision: 0.7442 - val_recall: 0.6799 - val_f1_score: 0.7104\n",
            "Epoch 3/5\n",
            "44140/44140 [==============================] - 52s 1ms/step - loss: 0.3620 - accuracy: 0.8616 - precision: 0.8680 - recall: 0.8423 - f1_score: 0.8549 - val_loss: 0.6786 - val_accuracy: 0.7524 - val_precision: 0.7632 - val_recall: 0.7108 - val_f1_score: 0.7360\n",
            "Epoch 4/5\n",
            "44140/44140 [==============================] - 51s 1ms/step - loss: 0.2231 - accuracy: 0.9179 - precision: 0.9284 - recall: 0.9149 - f1_score: 0.9216 - val_loss: 0.7890 - val_accuracy: 0.7479 - val_precision: 0.7714 - val_recall: 0.7021 - val_f1_score: 0.7349\n",
            "Epoch 5/5\n",
            "44140/44140 [==============================] - 52s 1ms/step - loss: 0.1461 - accuracy: 0.9473 - precision: 0.9568 - recall: 0.9542 - f1_score: 0.9555 - val_loss: 0.9002 - val_accuracy: 0.7475 - val_precision: 0.7712 - val_recall: 0.7044 - val_f1_score: 0.7361\n",
            "CPU times: user 8min 45s, sys: 1min 27s, total: 10min 12s\n",
            "Wall time: 4min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCmMEtibFWj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "28b6315d-d658-4b89-ff95-f5c3a8a6583c"
      },
      "source": [
        "gru_arabicnews.evaluate(x_test_seq, y_test) "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5518/5518 [==============================] - 1s 267us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8711209236041667,\n",
              " 0.7493656873703003,\n",
              " 0.7681520581245422,\n",
              " 0.7023904919624329,\n",
              " 0.7335846424102783]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j--N4bCpFdx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba57d6f0-98aa-42a7-beae-b30078b19346"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = gru_arabicnews.to_json()\n",
        "with open(\"/content/drive/My Drive/3-class/gru_arabicnews/gru_arabicnews.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "gru_arabicnews.save_weights(\"/content/drive/My Drive/3-class/gru_arabicnews/gru_arabicnews.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iRuRb6KFjVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9209ecc6-156b-444b-dd1e-c978a2a51cbc"
      },
      "source": [
        "shutil.move('/content/logs/gru_arabicnews','/content/drive/My Drive/3-class/gru_arabicnews/gru_arabicnews')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3-class/gru_arabicnews/gru_arabicnews'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lA2TN-wIFmcx"
      },
      "source": [
        "#**GRU-Fasttext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5jDSGuqcFmc2",
        "colab": {}
      },
      "source": [
        "num_words = 100000\n",
        "embedding_matrix_fasttext = np.zeros((num_words, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i >= num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index_fasttext.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix_fasttext[i] = embedding_vector"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iFusDgY-Fmc9",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=\"./logs/gru_fasttext\")\n",
        "keras_callbacks = [tensorboard]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0lFMn8ezFmdB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "457a8ac0-0212-4f13-a838-bafa9c4a1011"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "gru_fasttext = Sequential() \n",
        "e = Embedding(100000, 300, weights=[embedding_matrix_fasttext], input_length=tweetlen\n",
        "              , trainable=True)\n",
        "gru_fasttext.add(e)\n",
        "gru_fasttext.add(keras.layers.GRU(100, dropout=0.2))\n",
        "gru_fasttext.add(Dense(3, activation='softmax'))\n",
        "gru_fasttext.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), \n",
        "                           keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "print(gru_fasttext.summary())\n",
        "history = gru_fasttext.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=64, callbacks=keras_callbacks)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
            "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 29, 300)           30000000  \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 100)               120300    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 30,120,603\n",
            "Trainable params: 30,120,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44140 samples, validate on 5517 samples\n",
            "Epoch 1/5\n",
            "  256/44140 [..............................] - ETA: 2:57 - loss: 1.1030 - accuracy: 0.3047 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.160849). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "44140/44140 [==============================] - 54s 1ms/step - loss: 0.6468 - accuracy: 0.7243 - precision: 0.6951 - recall: 0.5108 - f1_score: 0.5791 - val_loss: 0.5321 - val_accuracy: 0.7763 - val_precision: 0.8318 - val_recall: 0.7233 - val_f1_score: 0.7736\n",
            "Epoch 2/5\n",
            "44140/44140 [==============================] - 53s 1ms/step - loss: 0.3204 - accuracy: 0.8792 - precision: 0.9011 - recall: 0.8728 - f1_score: 0.8867 - val_loss: 0.5835 - val_accuracy: 0.7863 - val_precision: 0.8147 - val_recall: 0.7660 - val_f1_score: 0.7895\n",
            "Epoch 3/5\n",
            "44140/44140 [==============================] - 52s 1ms/step - loss: 0.1359 - accuracy: 0.9515 - precision: 0.9662 - recall: 0.9582 - f1_score: 0.9622 - val_loss: 0.7158 - val_accuracy: 0.7673 - val_precision: 0.8055 - val_recall: 0.7424 - val_f1_score: 0.7725\n",
            "Epoch 4/5\n",
            "44140/44140 [==============================] - 52s 1ms/step - loss: 0.0664 - accuracy: 0.9768 - precision: 0.9859 - recall: 0.9835 - f1_score: 0.9847 - val_loss: 0.9127 - val_accuracy: 0.7633 - val_precision: 0.7932 - val_recall: 0.7549 - val_f1_score: 0.7735\n",
            "Epoch 5/5\n",
            "44140/44140 [==============================] - 52s 1ms/step - loss: 0.0372 - accuracy: 0.9874 - precision: 0.9931 - recall: 0.9905 - f1_score: 0.9918 - val_loss: 1.0521 - val_accuracy: 0.7602 - val_precision: 0.7703 - val_recall: 0.7789 - val_f1_score: 0.7744\n",
            "CPU times: user 8min 51s, sys: 1min 26s, total: 10min 18s\n",
            "Wall time: 4min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9U1LPaWBFmdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9b1a2de1-23b0-4f03-8b8c-d2713c939e86"
      },
      "source": [
        "gru_fasttext.evaluate(x_test_seq, y_test) "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5518/5518 [==============================] - 2s 272us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9696776766671612,\n",
              " 0.7635012865066528,\n",
              " 0.7547324299812317,\n",
              " 0.7658985257148743,\n",
              " 0.7597850561141968]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BttHRD52FmdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13d4308c-f93b-4687-ec6b-805e237050cf"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = gru_fasttext.to_json()\n",
        "with open(\"/content/drive/My Drive/3-class/gru_fasttext/gru_fasttext.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "gru_fasttext.save_weights(\"/content/drive/My Drive/3-class/gru_fasttext/gru_fasttext.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SB3Qyx-IFmdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70239fcf-ca74-4a54-a9c3-44545c35b07d"
      },
      "source": [
        "shutil.move('/content/logs/gru_fasttext','/content/drive/My Drive/3-class/gru_fasttext/gru_fasttext')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/3-class/gru_fasttext/gru_fasttext'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    }
  ]
}